{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e800f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3004fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6543214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d111382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6313fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# define paths to the original client and imposter folders\n",
    "path = r\"C:\\Users\\PRANNOY\\Downloads\\raw\\raw\"\n",
    "client_path = os.path.join(path, \"ClientRaw\")\n",
    "imposter_path = os.path.join(path, \"ImposterRaw\")\n",
    "\n",
    "# create new folders for train and test sets\n",
    "train_path = os.path.join(path, \"train\")\n",
    "test_path = os.path.join(path, \"test\")\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "# copy a portion of the images from the original folders to the train and test sets\n",
    "for folder_name in os.listdir(client_path):\n",
    "    folder_path = os.path.join(client_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        images = os.listdir(folder_path)\n",
    "        num_train_images = int(len(images) * 0.8)\n",
    "        for i, image_name in enumerate(images):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            if i < num_train_images:\n",
    "                target_path = os.path.join(train_path, \"client\", folder_name)\n",
    "            else:\n",
    "                target_path = os.path.join(test_path, \"client\", folder_name)\n",
    "            os.makedirs(target_path, exist_ok=True)\n",
    "            shutil.copy2(image_path, target_path)\n",
    "\n",
    "for folder_name in os.listdir(imposter_path):\n",
    "    folder_path = os.path.join(imposter_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        images = os.listdir(folder_path)\n",
    "        num_train_images = int(len(images) * 0.8)\n",
    "        for i, image_name in enumerate(images):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            if i < num_train_images:\n",
    "                target_path = os.path.join(train_path, \"imposter\", folder_name)\n",
    "            else:\n",
    "                target_path = os.path.join(test_path, \"imposter\", folder_name)\n",
    "            os.makedirs(target_path, exist_ok=True)\n",
    "            shutil.copy2(image_path, target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722a69e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10105 images belonging to 2 classes.\n",
      "Found 2509 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create an ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# set the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# set the paths to the train and test directories\n",
    "train_path = r'C:\\Users\\PRANNOY\\Downloads\\raw\\raw\\train'\n",
    "test_path = r'C:\\Users\\PRANNOY\\Downloads\\raw\\raw\\test'\n",
    "\n",
    "# create the train and test generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec5a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "315/315 [==============================] - 3300s 10s/step - loss: 0.1101 - accuracy: 0.9685 - val_loss: 0.0863 - val_accuracy: 0.9486\n",
      "Epoch 2/3\n",
      "315/315 [==============================] - 23728s 75s/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.2835 - val_accuracy: 0.9330\n",
      "Epoch 3/3\n",
      "315/315 [==============================] - 2337s 7s/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.3048 - val_accuracy: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b64766410>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# freeze the weights of the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add a new classifier on top of the pre-trained layers\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs=3,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples/test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c569b138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 437s 6s/step - loss: 0.3048 - accuracy: 0.9334\n",
      "Test accuracy: 0.9334396123886108\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "\n",
    "# print the test accuracy\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7485361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('liveness_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b6d1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists('liveness_detection_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52004f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRANNOY\\Desktop\\Jupyter notebooks\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9bd0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'captured_images', 'captured_images_faak', 'captured_images_fake', 'captured_photos', 'liveness_detection.ipynb', 'liveness_detection_model.h5', 'loaded_model.ipynb', 'Making_work.ipynb', 'Untitled.ipynb', 'WEBCAM CLICKS.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
